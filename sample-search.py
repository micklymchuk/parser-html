#!/usr/bin/env python3
"""
–ü–æ—à—É–∫ –ø–æ –±–∞–∑—ñ –¥–∞–Ω–∏—Ö - –∑–º—ñ–Ω—ñ—Ç—å —à–ª—è—Ö –¥–æ –ë–î —ñ –∑–∞–ø–∏—Ç
"""

from html_rag import create_pipeline

# ========== –ó–ú–Ü–ù–Ü–¢–¨ –¶–ï ==========
DB_PATH = "./database"           # –®–ª—è—Ö –¥–æ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
SEARCH_QUERY = "–∑–Ω–∞–π–¥–∏ —Ö—Ç–æ –ø—Ä–æ—Ç–∏ –ø—Ä–∏–≤–∞—Ç–∏–∑–∞—Ü—ñ—ó"      # –©–æ —à—É–∫–∞—Ç–∏
# ==============================

def main():
    print(f"üîç –®—É–∫–∞—é: '{SEARCH_QUERY}'")
    print(f"üìÇ –í –±–∞–∑—ñ: {DB_PATH}")

    # –ü—ñ–¥–∫–ª—é—á–∞—î–º–æ—Å—è –¥–æ –±–∞–∑–∏
    pipeline = create_pipeline(db_path=DB_PATH)

    # –®—É–∫–∞—î–º–æ (–±–µ–∑ –æ–±–º–µ–∂–µ–Ω—å, –≤—Å—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏)
    results = pipeline.topic_aware_search(
        query=SEARCH_QUERY,
        n_results=10             # –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    )

    print(f"\nüìã –ó–Ω–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤:\n")

    # –í–∏–≤–æ–¥–∏–º–æ –≤—Å–µ —â–æ –∑–Ω–∞–π—à–ª–∏
    for i, result in enumerate(results, 1):
        text = result['text']
        score = result['similarity_score']
        metadata = result.get('metadata', {})
        source = metadata.get('url', '–ù–µ–≤—ñ–¥–æ–º–µ –¥–∂–µ—Ä–µ–ª–æ')

        print(f"--- –†–µ–∑—É–ª—å—Ç–∞—Ç {i} ---")
        print(f"–°—Ö–æ–∂—ñ—Å—Ç—å: {score:.3f}")
        print(f"–î–∂–µ—Ä–µ–ª–æ: {source}")
        print(f"–¢–µ–∫—Å—Ç: {text}")
        print(f"Metadata: {metadata}")
        print("-" * 50)

if __name__ == "__main__":
    main()